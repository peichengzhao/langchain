{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c1f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zpc/anaconda3/envs/langchain/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "from openai import api_key, base_url\n",
    "from transformers import Qwen2_5_VLConfig\n",
    "# llm = ChatOpenAI(model=)\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"sk-C3gsaWJaOsmjrNv1fIobc4zEEsEkD15T98j80Vc8mNuSE420\")\n",
    "# llm = ChatOpenAI(model=\"o3-mini\", api_key=OPENAI_API_KEY, base_url=\"https://api.deepbricks.ai/v1/\")\n",
    "# QWEN_API_KEY = os.getenv(\"QWEN_API_KEY\", \"sk-ypjnechwutigvbyglbkguukzsmzkkxfibauydwkbjrypwojd\")\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-32B\", api_key=\"sk-qrqzhcsqektnkbfnrszxhfkcvhbpcmqoihoffxsizuvvkiwn\", base_url=\"https://api.siliconflow.cn/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c843afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "from langchain.prompts import example_selector\n",
    "examples = [\n",
    "    {\"input\": \"开心\", \"output\": \"伤心\"},\n",
    "    {\"input\": \"快乐\", \"output\": \"难过\"},\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"精力充沛\", \"output\":\"没精打采\"},\n",
    "    {\"input\": \"粗\", \"output\": \"细\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"输入: {input}\\n输出: {output}\"\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=40\n",
    ")\n",
    "\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"给出每个输入的反义词\",\n",
    "    suffix=\"输入: {adjective}\\n输出:\",\n",
    "    input_variables=[\"adjective\"],\n",
    "    example_separator=\"\\n\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4558c9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['adjective'], input_types={}, partial_variables={}, example_selector=LengthBasedExampleSelector(examples=[{'input': '开心', 'output': '伤心'}, {'input': '快乐', 'output': '难过'}, {'input': '高', 'output': '矮'}, {'input': '精力充沛', 'output': '没精打采'}, {'input': '粗', 'output': '细'}, {'input': '胖', 'output': '瘦'}], example_prompt=PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='输入: {input}\\n输出: {output}'), get_text_length=<function _get_length_based at 0x7f866d00bb50>, max_length=40, example_text_lengths=[4, 4, 4, 4, 4, 4]), example_prompt=PromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, template='输入: {input}\\n输出: {output}'), suffix='输入: {adjective}\\n输出:', example_separator='\\n', prefix='给出每个输入的反义词')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "new_example = {\"input\": \"胖\", \"output\": \"瘦\"}\n",
    "\n",
    "dynamic_prompt.example_selector.add_example(new_example)\n",
    "\n",
    "dynamic_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6642ff4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n输出: 不幸'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyexpat import model\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = dynamic_prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"adjective\": \"幸福\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00fad27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123070/118519743.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=embedding_path)\n"
     ]
    }
   ],
   "source": [
    "#相\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.prompts.example_selector import MaxMarginalRelevanceExampleSelector, SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_path = \"/home/zpc/langchain/blibli/bge-large-zh-v1.5\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_path)\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\"input\": \"开心\", \"output\": \"伤心\"},\n",
    "    {\"input\": \"快乐\", \"output\": \"难过\"},\n",
    "    {\"input\": \"高\", \"output\": \"矮\"},\n",
    "    {\"input\": \"精力充沛\", \"output\":\"没精打采\"},\n",
    "    {\"input\": \"粗\", \"output\": \"细\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3516946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embeddings,\n",
    "    FAISS,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "mmr_prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix = \"给出每个输入的反义词\",\n",
    "    suffix = \"Input: {adjective}\\nOutput:\",\n",
    "    input_variables = [\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "484c4a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给出每个输入的反义词\n",
      "\n",
      "Input: 快乐\n",
      "Output: 难过\n",
      "\n",
      "Input: 粗\n",
      "Output: 细\n",
      "\n",
      "Input: 幸福\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(mmr_prompt.format(adjective=\"幸福\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2abf0061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOutput: 痛苦'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = mmr_prompt | llm | output_parser\n",
    "chain.invoke({\"adjective\": \"幸福\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e23219b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 乾隆和曹操谁活得更久?\n",
      "\n",
      "这里是否需要跟进问题：是的。\n",
      "追问：乾隆去世时几岁？\n",
      "中间答案：乾隆去世时87岁。\n",
      "追问：曹操去世时几岁？\n",
      "中间答案：曹操去世时66岁。\n",
      "所以最终答案是：乾隆\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"乾隆和曹操谁活得更久?\",\n",
    "        \"answer\": \"\"\"\n",
    "这里是否需要跟进问题：是的。\n",
    "追问：乾隆去世时几岁？\n",
    "中间答案：乾隆去世时87岁。\n",
    "追问：曹操去世时几岁？\n",
    "中间答案：曹操去世时66岁。\n",
    "所以最终答案是：乾隆\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"小米手机的创始人什么时候出生?\",\n",
    "        \"answer\": \"\"\"\n",
    "这里是否需要跟进问题：是的。\n",
    "追问：小米手机的创始人是谁？\n",
    "中间答案：小米手机 由 雷军 创立。\n",
    "跟进：雷军什么时候出生？\n",
    "中间答案：雷军出生于 1969 年 12 月 16 日。\n",
    "所以最终的答案是：1969 年 12 月 16 日\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"乔治·华盛顿的外祖父是谁？\",\n",
    "        \"answer\": \"\"\"\n",
    "这里是否需要跟进问题：是的。\n",
    "追问：乔治·华盛顿的母亲是谁？\n",
    "中间答案：乔治·华盛顿的母亲是玛丽·鲍尔·华盛顿。\n",
    "追问：玛丽·鲍尔·华盛顿的父亲是谁？\n",
    "中间答案：玛丽·鲍尔·华盛顿的父亲是约瑟夫·鲍尔。\n",
    "所以最终答案是：约瑟夫·鲍尔\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\",\n",
    "        \"answer\": \"\"\"\n",
    "这里是否需要跟进问题：是的。\n",
    "追问：《大白鲨》的导演是谁？\n",
    "中间答案：《大白鲨》的导演是史蒂文·斯皮尔伯格。\n",
    "追问：史蒂文·斯皮尔伯格来自哪里？\n",
    "中间答案：美国。\n",
    "追问：皇家赌场的导演是谁？\n",
    "中间答案：《皇家赌场》的导演是马丁·坎贝尔。\n",
    "跟进：马丁·坎贝尔来自哪里？\n",
    "中间答案：新西兰。\n",
    "所以最终的答案是：不会\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\"\n",
    ")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8623795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 乾隆和曹操谁活得更久?\n",
      "\n",
      "这里是否需要跟进问题：是的。\n",
      "追问：乾隆去世时几岁？\n",
      "中间答案：乾隆去世时87岁。\n",
      "追问：曹操去世时几岁？\n",
      "中间答案：曹操去世时66岁。\n",
      "所以最终答案是：乾隆\n",
      "\n",
      "\n",
      "Question: 小米手机的创始人什么时候出生?\n",
      "\n",
      "这里是否需要跟进问题：是的。\n",
      "追问：小米手机的创始人是谁？\n",
      "中间答案：小米手机 由 雷军 创立。\n",
      "跟进：雷军什么时候出生？\n",
      "中间答案：雷军出生于 1969 年 12 月 16 日。\n",
      "所以最终的答案是：1969 年 12 月 16 日\n",
      "\n",
      "\n",
      "Question: 乔治·华盛顿的外祖父是谁？\n",
      "\n",
      "这里是否需要跟进问题：是的。\n",
      "追问：乔治·华盛顿的母亲是谁？\n",
      "中间答案：乔治·华盛顿的母亲是玛丽·鲍尔·华盛顿。\n",
      "追问：玛丽·鲍尔·华盛顿的父亲是谁？\n",
      "中间答案：玛丽·鲍尔·华盛顿的父亲是约瑟夫·鲍尔。\n",
      "所以最终答案是：约瑟夫·鲍尔\n",
      "\n",
      "\n",
      "Question: 《大白鲨》和《皇家赌场》的导演是同一个国家的吗？\n",
      "\n",
      "这里是否需要跟进问题：是的。\n",
      "追问：《大白鲨》的导演是谁？\n",
      "中间答案：《大白鲨》的导演是史蒂文·斯皮尔伯格。\n",
      "追问：史蒂文·斯皮尔伯格来自哪里？\n",
      "中间答案：美国。\n",
      "追问：皇家赌场的导演是谁？\n",
      "中间答案：《皇家赌场》的导演是马丁·坎贝尔。\n",
      "跟进：马丁·坎贝尔来自哪里？\n",
      "中间答案：新西兰。\n",
      "所以最终的答案是：不会\n",
      "\n",
      "\n",
      "Question: 李白和白居易谁活得更久\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples= examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\\nAnswer:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "print(prompt.format(input=\"李白和白居易谁活得更久\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "888831a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n这里是否需要跟进问题：是的。  \\n追问：李白去世时几岁？  \\n中间答案：李白去世时61岁。  \\n追问：白居易去世时几岁？  \\n中间答案：白居易去世时74岁。  \\n所以最终答案是：白居易'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"input\": \"李白和白居易谁活得更久？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af95a5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最相近的案例是[{'question': '乾隆和曹操谁活得更久?', 'answer': '\\n这里是否需要跟进问题：是的。\\n追问：乾隆去世时几岁？\\n中间答案：乾隆去世时87岁。\\n追问：曹操去世时几岁？\\n中间答案：曹操去世时66岁。\\n所以最终答案是：乾隆\\n'}]\n"
     ]
    }
   ],
   "source": [
    "import select\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "examples_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    embeddings,\n",
    "    Chroma,\n",
    "    k=1\n",
    "    )\n",
    "\n",
    "question = \"李白和白居易谁活得更久\"\n",
    "\n",
    "selected_examples = examples_selector.select_examples({\"question\": question})\n",
    "print(f\"最相近的案例是{selected_examples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68d198f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Answer:  \n",
      "Question: 李白和白居易谁活得更久?  \n",
      "这里是否需要跟进问题：是的。  \n",
      "追问：李白去世时几岁？  \n",
      "中间答案：李白去世时61岁。  \n",
      "追问：白居易去世时几岁？  \n",
      "中间答案：白居易去世时74岁。  \n",
      "所以最终答案是：白居易\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=examples_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix = \"请根据案例的方式来回答问题 . \\n\",\n",
    "    suffix=\"Question: {input}\\nAnswer:\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "print(chain.invoke({\"input\": \"李白和白居易谁活得更久\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7cd84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983a5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab64349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26a28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1128eb72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4b191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc63de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
